{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXoIPvtR5D8G"
      },
      "outputs": [],
      "source": [
        "# Depending on use cases, you will likely want to fork the original NIAH github repository to make changes easily\n",
        "\n",
        "%pip install -e \"git+https://github.com/gkamradt/LLMTest_NeedleInAHaystack#egg=needlehaystack\"\n",
        "%pip install ipywidgets\n",
        "%pip install tensorflow\n",
        "%pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2zq8Fsh9Xr2"
      },
      "outputs": [],
      "source": [
        "# Place API keys here, Model key needs OpenAI key for GPT models, or HuggingFace key for Llama/other models\n",
        "# Evaluator Key is always OpenAI key\n",
        "%env NIAH_MODEL_API_KEY = \"\"\n",
        "%env HUGGINGFACEHUB_API_TOKEN = \"\"\n",
        "%env NIAH_EVALUATOR_API_KEY = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9_XLg7lGkyA"
      },
      "outputs": [],
      "source": [
        "# Example of a single needle test for Llama 3.2 3B Instruct\n",
        "# Note that some models such as 8B will require 40+ GB of GPU/VRAM at 128k token context lengths and will need to use Colab Pro, Google Cloud, or Enterprise for high RAM GPUs\n",
        "!needlehaystack.run_test --provider huggingface --model_name \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\" --document_depth_percents \"[10,16,23,29,35,42,48,55,61,68,74,80,87,93,100]\" --context_lengths \"[1000,2000,4000,8000, 16000, 32000, 64000, 128000]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvfw34i7GkPz"
      },
      "outputs": [],
      "source": [
        "# Example of Random multi needle test with the Pause Token 1 test, note that document depth percents is the same as single needle, the percents don't affect the test, each test is random and there are 15 document depths, resulting in 15 randomized trials.\n",
        "# To properly run the multi needle test, the needle and question in the run.py file will need to be altered.\n",
        "\n",
        "!needlehaystack.run_test --provider huggingface --model_name \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\" --document_depth_percents \"[10,16,23,29,35,42,48,55,61,68,74,80,87,93,100]\" --context_lengths \"[1000,2000,4000,8000, 16000, 32000, 64000, 128000]\" --multi_needle True --multi_needle_type \"random\" --haystack_dir \"/content/src/needlehaystack/Test1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osTR69AYPB_q"
      },
      "outputs": [],
      "source": [
        " #run this to zip the results then download it, much faster than downloading individually\n",
        "\n",
        "!zip -r results.zip results/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
